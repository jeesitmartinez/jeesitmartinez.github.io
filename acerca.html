<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning - Acerca de</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
   <!-- Header -->
  <header>
    <div class="container header-container">
      <div class="logo">
        <div class="logo-img">
          <img src="img/logo1.png" alt="Logo Machine Learning">
        </div>
        <h1>Machine Learning</h1>
      </div>
      <nav>
        <ul>
          <li><a href="index.html">Inicio</a></li>
          <li><a href="acerca.html">Acerca de</a></li>
          <li><a href="contacto.html">Contacto</a></li>
        </ul>
      </nav>
    </div>
  </header>
</body>
</html>

    <main class="container">
        <section class="hero">
            <h2>Acerca del Machine Learning</h2>
            <p>Conoce m√°s sobre esta revolucionaria tecnolog√≠a que est√° transformando el mundo.</p>
        </section>
        
        <section class="content-section">
            <article>
                <h3>Historia del Machine Learning</h3>
                <p>El concepto de Machine Learning tiene sus ra√≠ces en la d√©cada de 1950, cuando Alan Turing propuso la idea de m√°quinas que pudieran aprender. Sin embargo, no fue hasta la d√©cada de 1990 que el campo realmente despeg√≥ gracias al aumento en la capacidad de procesamiento y la disponibilidad de grandes conjuntos de datos.</p>
                
                <h3>Algoritmos Detallados</h3>
                
                <div class="algorithm-card">
                    <h4>Regresi√≥n Lineal <span class="algorithm-icon">üìà</span></h4>
                    <div class="algorithm-content">
                        <p>Algoritmo de aprendizaje supervisado utilizado para predecir un valor continuo. Su objetivo es encontrar una relaci√≥n lineal entre una variable dependiente y una o m√°s variables independientes.</p>
                        <p>La regresi√≥n lineal simple utiliza una sola variable predictora, mientras que la regresi√≥n lineal m√∫ltiple utiliza varias. Es uno de los algoritmos m√°s fundamentales en ML y sirve como base para t√©cnicas m√°s avanzadas.</p>
                        <p><strong>Aplicaciones:</strong> Predicci√≥n de precios de viviendas, pron√≥stico de ventas, an√°lisis de tendencias econ√≥micas.</p>
                        <p><strong>Ventajas:</strong> Simple de implementar e interpretar, computacionalmente eficiente.</p>
                        <p><strong>Limitaciones:</strong> Asume una relaci√≥n lineal, sensible a valores at√≠picos.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <div class="algorithm-card">
                    <h4>Regresi√≥n Log√≠stica <span class="algorithm-icon">üîç</span></h4>
                    <div class="algorithm-content">
                        <p>A pesar de su nombre, es un algoritmo de aprendizaje supervisado para clasificaci√≥n. Predice la probabilidad (de 0 a 1) de que un dato pertenezca a una categor√≠a espec√≠fica.</p>
                        <p>Utiliza la funci√≥n sigmoide para transformar la salida lineal en una probabilidad. Es ampliamente utilizado en problemas de clasificaci√≥n binaria, pero puede extenderse a clasificaci√≥n multiclase.</p>
                        <p><strong>Aplicaciones:</strong> Diagn√≥stico m√©dico (enfermo/sano), detecci√≥n de spam, an√°lisis de riesgo crediticio.</p>
                        <p><strong>Ventajas:</strong> Proporciona probabilidades, f√°cil de regularizar, eficiente computacionalmente.</p>
                        <p><strong>Limitaciones:</strong> Asume relaci√≥n lineal entre caracter√≠sticas y el logaritmo de la probabilidad.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <div class="algorithm-card">
                    <h4>√Årboles de Decisi√≥n <span class="algorithm-icon">üå≥</span></h4>
                    <div class="algorithm-content">
                        <p>Algoritmo de aprendizaje supervisado que puede usarse para clasificaci√≥n y regresi√≥n. Su funcionamiento imita a c√≥mo un humano toma decisiones mediante una serie de preguntas de s√≠/no.</p>
                        <p>Los √°rboles dividen los datos en subconjuntos basados en el valor de las caracter√≠sticas, creando una estructura jer√°rquica. Cada nodo interno representa una prueba sobre una caracter√≠stica, cada rama representa el resultado de la prueba, y cada nodo hoja representa una etiqueta de clase.</p>
                        <p><strong>Aplicaciones:</strong> Diagn√≥stico m√©dico, evaluaci√≥n de riesgo, segmentaci√≥n de clientes.</p>
                        <p><strong>Ventajas:</strong> F√°cil de entender e interpretar, puede manejar tanto caracter√≠sticas num√©ricas como categ√≥ricas.</p>
                        <p><strong>Limitaciones:</strong> Propensos a sobreajuste, sensibles a peque√±os cambios en los datos.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <div class="algorithm-card">
                    <h4>Random Forest (Bosque Aleatorio) <span class="algorithm-icon">üå≤</span></h4>
                    <div class="algorithm-content">
                        <p>Algoritmo de ensamble que combina m√∫ltiples √Årboles de Decisi√≥n para crear un modelo m√°s potente y robusto. La idea central es: "La sabidur√≠a de las multitudes".</p>
                        <p>Cada √°rbol en el bosque se entrena con una muestra aleatoria de los datos (bootstrapping) y considera solo un subconjunto aleatorio de caracter√≠sticas en cada divisi√≥n. La predicci√≥n final se obtiene por votaci√≥n (clasificaci√≥n) o promediaci√≥n (regresi√≥n) de las predicciones de todos los √°rboles.</p>
                        <p><strong>Aplicaciones:</strong> Clasificaci√≥n de im√°genes, detecci√≥n de fraudes, predicci√≥n de precios.</p>
                        <p><strong>Ventajas:</strong> Alta precisi√≥n, resistente al sobreajuste, puede manejar grandes conjuntos de datos con muchas caracter√≠sticas.</p>
                        <p><strong>Limitaciones:</strong> Menos interpretable que un √°rbol individual, computacionalmente m√°s costoso.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <div class="algorithm-card">
                    <h4>M√°quinas de Vectores de Soporte (SVM) <span class="algorithm-icon">‚ö°</span></h4>
                    <div class="algorithm-content">
                        <p>Algoritmo de aprendizaje supervisado poderoso, principalmente para clasificaci√≥n. Su objetivo es encontrar el mejor l√≠mite de separaci√≥n (un "hiperplano") entre dos clases.</p>
                        <p>SVM busca maximizar el margen entre las clases, lo que conduce a una mejor generalizaci√≥n. Puede manejar datos linealmente separables usando kernels para transformar el espacio de caracter√≠sticas y hacerlos separables linealmente en un espacio de mayor dimensi√≥n.</p>
                        <p><strong>Aplicaciones:</strong> Reconocimiento de escritura a mano, clasificaci√≥n de texto, bioinform√°tica.</p>
                        <p><strong>Ventajas:</strong> Efectivo en espacios de alta dimensi√≥n, vers√°til gracias a diferentes funciones kernel.</p>
                        <p><strong>Limitaciones:</strong> No funciona bien con conjuntos de datos muy grandes, sensible a la elecci√≥n de par√°metros.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <div class="algorithm-card">
                    <h4>K-Vecinos M√°s Cercanos (K-NN) <span class="algorithm-icon">üìç</span></h4>
                    <div class="algorithm-content">
                        <p>Algoritmo de aprendizaje supervisado simple, usado principalmente para clasificaci√≥n y regresi√≥n. Es un algoritmo "perezoso" (lazy), lo que significa que no "aprende" un modelo durante el entrenamiento, sino que memoriza todos los datos.</p>
                        <p>Para hacer una predicci√≥n, K-NN encuentra los K puntos de datos m√°s cercanos al punto de consulta y toma una decisi√≥n basada en la mayor√≠a de votos (clasificaci√≥n) o el promedio (regresi√≥n) de estos vecinos.</p>
                        <p><strong>Aplicaciones:</strong> Sistemas de recomendaci√≥n, reconocimiento de patrones, diagn√≥stico m√©dico.</p>
                        <p><strong>Ventajas:</strong> Simple de entender e implementar, no necesita entrenamiento.</p>
                        <p><strong>Limitaciones:</strong> Computacionalmente costoso para grandes conjuntos de datos, sensible a la escala de las caracter√≠sticas.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <div class="algorithm-card">
                    <h4>K-Means <span class="algorithm-icon">üî¢</span></h4>
                    <div class="algorithm-content">
                        <p>Es el algoritmo de agrupaci√≥n (clustering) no supervisado m√°s popular. Su objetivo es dividir un conjunto de datos en K grupos (o "clusters") donde los puntos dentro de un mismo grupo sean lo m√°s similares posible entre s√≠, y lo m√°s diferentes posible a los puntos de otros grupos.</p>
                        <p>K-Means itera entre asignar puntos a clusters y recalcular los centroides de los clusters hasta que converge. La elecci√≥n del n√∫mero K de clusters es crucial y a menudo se determina usando m√©todos como el codo o silhouette.</p>
                        <p><strong>Aplicaciones:</strong> Segmentaci√≥n de clientes, compresi√≥n de im√°genes, an√°lisis de gen√©tica.</p>
                        <p><strong>Ventajas:</strong> Simple y r√°pido, escalable a grandes conjuntos de datos.</p>
                        <p><strong>Limitaciones:</strong> Sensible a la inicializaci√≥n, asume clusters esf√©ricos y de tama√±o similar.</p>
                    </div>
                    <span class="read-more">Ver m√°s...</span>
                </div>
                
                <h3>Temas Avanzados y Tendencias Actuales</h3>
                <ul>
                    <li><strong>Redes Neuronales y Aprendizaje Profundo (Deep Learning):</strong> Modelos inspirados en el cerebro humano, excelentes para datos no estructurados como im√°genes, audio y texto.</li>
                    <li><strong>Procesamiento del Lenguaje Natural (NLP):</strong> C√≥mo las m√°quinas entienden y generan lenguaje humano (ej: ChatGPT, traductores).</li>
                    <li><strong>Visi√≥n por Computadora (Computer Vision):</strong> Ense√±ar a las m√°quinas a "ver" y entender im√°genes y videos.</li>
                    <li><strong>√âtica y Sesgo en ML:</strong> C√≥mo los sesgos en los datos pueden llevar a modelos injustos y discriminatorios. Es un √°rea de cr√≠tica importancia.</li>
                    <li><strong>AutoML:</strong> Automatizar el proceso de construcci√≥n de modelos de ML.</li>
                </ul>
            </article>
            
            <aside>
                <h3>Flujo de Trabajo Detallado</h3>
                <ol>
                    <li><strong>Recolecci√≥n de Datos:</strong> Obtener datos de diversas fuentes (bases de datos, APIs, archivos CSV, etc.).</li>
                    <li><strong>Limpieza y Preprocesamiento:</strong> Manejar valores faltantes, corregir errores, codificar variables categ√≥ricas, escalar o normalizar los datos.</li>
                    <li><strong>An√°lisis Exploratorio de Datos (EDA):</strong> Usar estad√≠sticas y visualizaciones para entender los datos, encontrar correlaciones y detectar anomal√≠as.</li>
                    <li><strong>Ingenier√≠a de Caracter√≠sticas:</strong> Crear nuevas caracter√≠sticas a partir de las existentes para mejorar el rendimiento del modelo.</li>
                    <li><strong>Selecci√≥n y Entrenamiento del Modelo:</strong> Elegir un algoritmo (o varios) y entrenarlo con los datos.</li>
                    <li><strong>Evaluaci√≥n del Modelo:</strong> Medir el rendimiento del modelo utilizando datos que no vio durante el entrenamiento (conjunto de prueba).</li>
                    <li><strong>Ajuste de Hiperpar√°metros:</strong> Optimizar los ajustes del modelo para obtener el mejor rendimiento.</li>
                    <li><strong>Despliegue:</strong> Implementar el modelo en un entorno de producci√≥n para que pueda hacer predicciones sobre datos reales.</li>
                    <li><strong>Monitoreo y Mantenimiento:</strong> Supervisar el modelo para asegurarse de que su rendimiento no se degrade con el tiempo (concepto de "desfase de modelo" o model drift).</li>
                </ol>
                
              <h3>Enlaces de inter√©s</h3>
<div class="external-links">
    <a href="https://www.tensorflow.org/" target="_blank">
        <img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg" alt="TensorFlow">
        <span>TensorFlow</span>
    </a>
    <a href="https://pytorch.org/" target="_blank">
        <img src="https://upload.wikimedia.org/wikipedia/commons/1/10/PyTorch_logo_icon.svg" alt="PyTorch">
        <span>PyTorch</span>
    </a>
    <a href="https://www.kaggle.com/" target="_blank">
        <img src="https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png" alt="Kaggle">
        <span>Kaggle</span>
    </a>
    <a href="https://scikit-learn.org/" target="_blank">
        <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="Scikit-learn">
        <span>Scikit-learn</span>
    </a>
</div>
              
            </aside>
        </section>
    </main>

    <footer>
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>Machine Learning</h3>
                    <p>Explorando el futuro de la inteligencia artificial.</p>
                    <div class="social-links">
                        <a href="#">Facebook</a>
                        <a href="#">Twitter</a>
                        <a href="#">LinkedIn</a>
                        <a href="#">Instagram</a>
                    </div>
                </div>
                
                <div class="footer-section">
                    <h3>Enlaces r√°pidos</h3>
                    <ul>
                        <li><a href="index.html">Inicio</a></li>
                        <li><a href="acerca.html">Acerca de</a></li>
                        <li><a href="contacto.html">Contacto</a></li>
                    </ul>
                </div>
                
                <div class="footer-section">
                    <h3>Contacto</h3>
                    <p>Email: info@machinelearning.com</p>
                    <p>Tel√©fono: +1 234 567 890</p>
                </div>
            </div>
            
            <div class="copyright">
                <p>&copy; 2023 Machine Learning. Todos los derechos reservados.</p>
            </div>
        </div>
    </footer>

    <script src="js/script.js"></script>
</body>
</html>